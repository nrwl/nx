---
title: Optimize Testing with Feature-Based Testing
sidebar:
  label: Feature-Based Testing
description: Learn how to optimize your testing strategy by breaking down monolithic test projects into feature-scoped tests that run only when needed.
filter: 'type:Guides'
---

Feature-based testing is a strategy that co-locates tests with the features they verify. This approach helps you test only what's changed, reducing unnecessary test execution and improving feedback loops.

## The Problem: Monolithic Test Projects

Many projects start with a single, large test project that depends on the entire application. While this setup ensures tests run when any dependency changes, it also means **all tests run even when only one feature changes**.

{% aside type="tip" title="Beyond E2E Tests" %}
While this guide uses end-to-end (e2e) tests as examples, the same strategy applies to any type of testing—integration tests, component tests, or even large unit test suites. The principles of feature-based testing work wherever you have monolithic test projects that could benefit from being split by feature.
{% /aside %}

Consider a typical setup where all e2e tests live in a single project:
{% graph height="400px" %}

```json
{
  "projects": [
    {
      "name": "fancy-app-e2e",
      "type": "app",
      "data": {
        "tags": []
      }
    },
    {
      "name": "fancy-app",
      "type": "app",
      "data": {
        "tags": []
      }
    },
    {
      "name": "shared-ui",
      "type": "lib",
      "data": {
        "tags": []
      }
    },
    {
      "name": "feat-cart",
      "type": "lib",
      "data": {
        "tags": []
      }
    },
    {
      "name": "feat-products",
      "type": "lib",
      "data": {
        "tags": []
      }
    }
  ],
  "dependencies": {
    "fancy-app-e2e": [
      { "source": "fancy-app-e2e", "target": "fancy-app", "type": "implicit" }
    ],
    "fancy-app": [
      { "source": "fancy-app", "target": "feat-products", "type": "static" },
      { "source": "fancy-app", "target": "feat-cart", "type": "static" }
    ],
    "shared-ui": [],
    "feat-cart": [
      {
        "source": "feat-cart",
        "target": "shared-ui",
        "type": "static"
      }
    ],
    "feat-products": [
      {
        "source": "feat-products",
        "target": "shared-ui",
        "type": "static"
      }
    ]
  },
  "workspaceLayout": { "appsDir": "", "libsDir": "" },
  "affectedProjectIds": [],
  "groupByFolder": false,
  "showAffectedWithNodes": true
}
```

{% /graph %}

In this example, when `feat-cart` changes, **all tests in `fancy-app-e2e` run**—including tests for `feat-products` and other unrelated features. This happens because `fancy-app-e2e` depends on the entire application.

Since these features have minimal overlap, you can optimize testing by splitting the monolithic test project into smaller, feature-scoped test projects.

## The Solution: Feature-Scoped Testing

Instead of keeping all tests in one large project, break them down by feature and co-locate them with the feature libraries they test. This way, only the tests for changed features run.

### How to Implement Feature-Based Testing

To set up feature-based testing, add test configurations directly to your feature projects. This includes adding your testing targets to the project, e.g. `test`, `e2e`. Next, add any relevant configuration files for your testing framework of choice.

Nx provides plugins to automate and speed up the testing configuration for common testing frameworks:
- [Playwright](/docs/technologies/test-tools/playwright/introduction#add-playwright-e2e-to-an-existing-project)
- [Cypress](/docs/technologies/test-tools/cypress/introduction#configure-cypress-for-an-existing-project)
- [Vitest](/docs/technologies/build-tools/vite/generators#configuration)
- [Jest](/docs/technologies/test-tools/jest/introduction#add-jest-to-a-project)

The end result of refactoring testing into the feature project level results in:

- **Focused testing**: Tests only run when their specific feature changes
- **Faster feedback**: Smaller test suites complete more quickly
- **Better organization**: Tests live alongside the code they verify

### Understanding the Task Graph changes

The project graph structure remains the same, but the task graph changes to more closely align with the project graph.
Before we only has 1 single task `fancy-app-e2e:e2e` that ran all tests. The feature-based setup creates multiple tasks mapping to each project containing the feature.

{% graph type="task" height="300px" %}

```json
{
  "projects": [
    {
      "name": "fancy-app-e2e",
      "type": "app",
      "data": {
        "tags": [],
        "targets": {
          "e2e": {}
        }
      }
    },
    {
      "name": "fancy-app",
      "type": "app",
      "data": {
        "tags": []
      }
    },
    {
      "name": "shared-ui",
      "type": "lib",
      "data": {
        "tags": []
      }
    },
    {
      "name": "feat-cart",
      "type": "lib",
      "data": {
        "tags": [],
        "targets": {
          "e2e": {}
        }
      }
    },
    {
      "name": "feat-products",
      "type": "lib",
      "data": {
        "tags": []
      }
    }
  ],
  "taskIds": ["fancy-app-e2e:e2e", "feat-cart:e2e"],
  "taskGraph": {
    "roots": ["feat-cart:e2e"],
    "tasks": {
      "fancy-app-e2e:e2e": {
        "id": "fancy-app-e2e:e2e",
        "target": {
          "project": "fancy-app-e2e",
          "target": "e2e"
        },
        "projectRoot": "apps/fancy-app-e2e",
        "overrides": {}
      },
      "feat-cart:e2e": {
        "id": "feat-cart:e2e",
        "target": {
          "project": "feat-cart",
          "target": "e2e"
        },
        "projectRoot": "libs/feat-cart",
        "overrides": {}
      }
    },
    "dependencies": {
      "fancy-app-e2e:e2e": ["feat-cart:e2e"]
    }
  }
}
```

{% /graph %}

In this task graph, when `feat-cart` changes:

- `feat-cart:e2e` runs only the cart specific tests
- `fancy-app-e2e:e2e` runs application wide tests such as smoke tests
- `feat-products:e2e` **does not run** since it wasn't affected)

This is the key optimization only relevant tests execute based on what changed.

## Best Practices

### Keep the Top-Level Test Project

Don't delete your top level test project,  `fancy-app-e2e` in this example. Instead, repurpose it for:

- **Smoke tests**: Quick sanity checks that the app starts and critical paths work
- **Cross-feature integration tests**: Tests that verify multiple features work together
- **End-to-end user journeys**: Tests that span multiple features

This gives you a balanced testing strategy: focused feature tests that run frequently, plus comprehensive integration tests when needed.

### Running Tests in Parallel

When running feature tests in parallel, be mindful of shared resources. Since all feature tests run against the same application instance, avoid conflicts by:

- **Using unique test data**: Don't rely on specific database records or application state
- **Managing ports**: Configure each test to use different ports, or let the test framework find free ports automatically
  - For Cypress, use the [`--port` flag](/nx-api/cypress/executors/cypress#port) to specify or auto-detect ports
  - For Playwright, the `webServerAddress` can be dynamically assigned
- **Isolating state**: Use test-specific user accounts, temporary data, or cleanup between tests

### Running Affected Tests

With feature-based testing, you can leverage Nx's affected commands to run only the tests that matter:

```shell
# Run all affected tests based on your changes
nx affected -t test

# Run affected e2e tests
nx affected -t e2e
```

This ensures you're only testing what changed, whether locally or in CI.

### Combining with Automated Task Splitting (Atomizer)

Feature-based testing and [Automated Task Splitting](/docs/features/ci-features/split-e2e-tasks) (also known as Atomizer) work great together. While feature-based testing breaks down tests by feature, Atomizer automatically splits individual test projects into file-level tasks for parallel execution.

Here's how they complement each other:

- **Feature-based testing** ensures only relevant feature tests run when code changes
- **Atomizer** splits each feature's test suite into individual file-level tasks that can be distributed across multiple CI agents

For example, if `feat-cart` has 10 test files and `feat-products` has 15 test files, when you change the cart feature:

1. Feature-based testing runs only `feat-cart:e2e-ci` (skipping `feat-products:e2e-ci`)
2. Atomizer splits `feat-cart:e2e-ci` into 10 parallel tasks, one per test file
3. These tasks get distributed across your CI agents for faster execution


Learn more about [setting up Automated Task Splitting](/docs/features/ci-features/split-e2e-tasks).
